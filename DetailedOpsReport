
# coding: utf-8

# In[1]:


from sqlalchemy import create_engine
import pandas as pd
import pandas.io.sql as psql
import  pymysql as pms
import numpy as np
pms.install_as_MySQLdb()
import os
import smtplib, os
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email.mime.text import MIMEText
from email.utils import COMMASPACE, formatdate
from email import encoders
from email.mime.image import MIMEImage
import datetime as dt
import json
import datetime

import requests
import datetime as dtt
import re
import base64
import urllib.request
import ssl
import base64
import json
import urllib
#import urllib2
from urllib.request import urlopen
from urllib.request import Request

import datetime
##### Orders transactions report
template_dir = r'D:\arammeem\reports'
os.chdir(template_dir)

engineDelivery = create_engine('postgresql://o.konoval@arammeem.com:@gw.app.arammeem.net:5432/amdelivery?sslmode=verify-full&sslrootcert=D:\\arammeem\keys\ca.crt&sslkey=D:\\arammeem\keys\client.key&sslcert=D:\\arammeem\keys\client.crt&sslcompression=1')
enginePayment= create_engine('postgresql://o.konoval@arammeem.com:@gw.app.arammeem.net:5432/ampayment?sslmode=verify-full&sslrootcert=D:\\arammeem\keys\ca.crt&sslkey=D:\\arammeem\keys\client.key&sslcert=D:\\arammeem\keys\client.crt&sslcompression=1')
engineDriver = create_engine('postgresql://o.konoval@arammeem.com:@gw.app.arammeem.net:5432/amdriver?sslmode=verify-full&sslrootcert=D:\\arammeem\keys\ca.crt&sslkey=D:\\arammeem\keys\client.key&sslcert=D:\\arammeem\keys\client.crt&sslcompression=1')
engineUser = create_engine('postgresql://o.konoval@arammeem.com:@gw.app.arammeem.net:5432/amuser?sslmode=verify-full&sslrootcert=D:\\arammeem\keys\ca.crt&sslkey=D:\\arammeem\keys\client.key&sslcert=D:\\arammeem\keys\client.crt&sslcompression=1')
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)


# In[ ]:


#### DRIVERS


# In[159]:


driver_address = pd.read_sql_query('''
    SELECT 
    driver_id
    ,name
    ,case when value like '%%Jeddah%%' then 'Jeddah'
    when value like '%%Riyadh%%' then 'Riyadh'
    when value like '%%Ш§Щ„Ш±ЩЉШ§Ш¶%%' then 'Riyadh'
    else value end as value
    FROM public.driver_address
    where name in ('city','country','state')
    ''', engineDriver)

driver_address = driver_address.set_index(['driver_id', 'name']).unstack(level=-1).reset_index()

driver_address.columns = ['driver_id','city','country','state']

driver_info = pd.read_sql_query('''
with driver_cat as
(
select
driver_id
,string_agg(category, ', ') AS category_list
,string_agg(main_service_type_id, ', ') AS main_service_type_list
,case when string_agg(category, ', ') like '%%DELREP%%' and string_agg(category, ', ') like '%%PTREP%%' then 1
when string_agg(category, ', ') like '%%COURREP%%' and string_agg(category, ', ') like '%%PTREP%%' then 1
else 0 end as to_del   
from
    (
    SELECT distinct 
    driver_id
    ,case 
    when main_service_type_id ='courier' then 'COURREP'
    when main_service_type_id in ('merchant-delivery-booking','delivery') then 'DELREP'
    when  main_service_type_id in ('taxi-econom','comfort','economy','Suv') then 'PTREP'
    else 'LBSREP' end as category
    ,case when main_service_type_id like '%%econo%%' then 'Smart' else main_service_type_id end as main_service_type_id
    FROM driver_active_service_type 
    order by driver_id, category, main_service_type_id

    ) b
group by
driver_id
)

select 
a.id as driver_id
,first_name
,last_name
,first_name_native
,last_name_native
,phone
,rating
,enabled
,is_saudi_arabia_citizen
,iban
,bank_account_name
,account_name
,driver_reward_type
,category_list
,main_service_type_list
from driver_cat d
join
driver_account a on a.id=d.driver_id
where d.to_del=0
and phone like '%%966%%' 
    ''', engineDriver)

driver_online = pd.read_sql_query('''
SELECT 
driver_id
,day as day_online_report
,sum(milliseconds_online)/3600000 as hours_online
FROM 
public.time_on_line
where day>cast(now() as date) -2
and day<cast(now() as date)
group by
driver_id
,day
                ''', engineDriver)


# In[161]:


max_accepted_date = pd.read_sql_query('''
SELECT 
driver
,max(cast((accepted_date + 3 * INTERVAL '1 hour') as date)) as last_day_taken_order 
FROM public.delivery_order
where accepted_date is not null
and (accepted_date + 3 * INTERVAL '1 hour')<cast(now() as date)
group by
driver
''', engineDelivery)

max_accepted_date['days_inactive'] = (dtt.datetime.now().date()-max_accepted_date.last_day_taken_order).dt.days-1


# In[162]:


driver_eta_base = pd.read_sql_query('''
SELECT 
delivery
,creation_date
,case when order_flow_event='ACCEPTED' then 0 else 1 end as ordero 
FROM public.order_flow_history
where order_flow_event in ('ACCEPTED','AT_PICK_UP')
and creation_date>now()- 30 * INTERVAL '1 day'
    ''', engineDelivery)

orders= pd.read_sql_query('''
select
id,
driver
from
delivery_order
where creation_date>now()- 31 * INTERVAL '1 day'
and driver is not null
''', engineDelivery)


# In[164]:


tmp = pd.merge(driver_eta_base, orders, how='inner', left_on='delivery', right_on='id').drop(columns=['id']).dropna()

tmp = tmp.groupby(by=['driver','delivery','ordero']).creation_date.max().unstack(level=-1).reset_index().dropna()

tmp['delta_eta'] = ((tmp[1]-tmp[0])/np.timedelta64(1,'m'))

tmp['delta_eta'] = np.array([round(x,1) for x in tmp['delta_eta'].values])

tmp = tmp.groupby(by='driver').delta_eta.mean().reset_index()

tmp['driver'] = tmp['driver'].astype(int)

finance=pd.read_sql_query('''
SELECT 
beneficiary_id
,cast((finished_date + 3 * INTERVAL '1 hour') as date) as finished_dt
,account_type
,tx_operation_type
,sum(amount) as total_amt
FROM public.tx_record
where beneficiary_type='DRIVER'
and record_state='SUCCESS'
and (finished_date + 3 * INTERVAL '1 hour')  >cast(now() as date) -1
and (finished_date + 3 * INTERVAL '1 hour')<cast(now() as date)
group by  
beneficiary_id
,cast((finished_date + 3 * INTERVAL '1 hour') as date)
,account_type
,tx_operation_type
    ''', enginePayment)

finance_pivot=pd.pivot_table(data=finance, index=['beneficiary_id'], columns=['account_type','tx_operation_type']                             , aggfunc={'total_amt':'sum'}).total_amt

finance_pivot.columns = [str(x) for x in list(finance_pivot.columns)]

finance_pivot=finance_pivot.reset_index()

finance_pivot['beneficiary_id']=finance_pivot['beneficiary_id'].astype(int)

current_balance=pd.read_sql_query('''
SELECT 
driver_id
,current_balance
FROM 
driver_current_balance

''', engineDriver)

driver_address.columns = ['driver_id','city','country','state']

tmp1 = pd.merge(driver_info,driver_address,how='left',left_on='driver_id', right_on='driver_id')

tmp1=pd.merge(tmp1, driver_online, how='left',left_on='driver_id', right_on='driver_id')

tmp1=pd.merge(tmp1, max_accepted_date, how='left',left_on='driver_id', right_on='driver')

tmp1=pd.merge(tmp1, tmp, how='left',left_on='driver_id', right_on='driver')

tmp1=pd.merge(tmp1, current_balance, how='left',left_on='driver_id', right_on='driver_id')

fin=pd.merge(tmp1, finance_pivot, how='left',left_on='driver_id', right_on='beneficiary_id')

fin=fin.drop(columns=['driver_x','driver_y','beneficiary_id'])

fin=fin.sort_values(by='days_inactive')


# In[ ]:


#### ORDERS


# In[165]:


orders= pd.read_sql_query('''
select
id
,operation_area
,order_number
,case when service_group='TAXI' then 'PT'
    when service_type='courier' then 'CD'
    when service_type like '%%merchant%%' then 'MBD'
    when service_type like '%%delivery%%' then 'DA'
    else 'LBS' end as Category
,service_type
,status
,customer_paid_state
,cast((invite_date + 3 * INTERVAL '1 hour') as date) as order_placed
,cast((invite_date + 3 * INTERVAL '1 hour') as time) as order_placed_time
,cast((creation_date + 3 * INTERVAL '1 hour') as date) as order_created
,cast((creation_date + 3 * INTERVAL '1 hour') as time) as order_created_time
,cast((finished_date + 3 * INTERVAL '1 hour') as date) as finished_date
,cast((finished_date + 3 * INTERVAL '1 hour') as time) as finished_date_time
,payment_type
,cost_calculation_result::json->'shown' as shown
,cost_calculation_result::json->'vat' as vat
,merchant_name
,driver
,customer_user_id
,l1.address as pick_up_location
,l2.address as drop_off_location
,merchant_id
,delivery_status
,cancelled_by
,reason
,requires_merchant_approval
,accepted_by_merchant
,merchant_order_reference
,asap
,drop_off_user_id
from
delivery_order o
left join
    (
    select
    location
    ,value as address
    from 
    (
            SELECT 
            location
            ,ROW_NUMBER() OVER(PARTITION BY location) AS rk
            ,value
            FROM location_attribute
            where name='addrLine1'
     ) a
    where rk=1

    ) l1 on l1.location=o.pick_up_location
    
left join
    (
    select
    location
    ,value as address
    from 
    (
            SELECT 
            location
            ,ROW_NUMBER() OVER(PARTITION BY location) AS rk
            ,value
            FROM location_attribute
            where name='addrLine1'
     ) a
    where rk=1

    ) l2 on l2.location=o.drop_off_location
    
where (finished_date + 3 * INTERVAL '1 hour')  >cast(now() as date) -1
and (finished_date + 3 * INTERVAL '1 hour')<cast(now() as date)
and coalesce(message, 'empty') not like '%%test%%'
''', engineDelivery)


df_shown = pd.DataFrame([x if str(x)!='None' else dict({}) for x in orders.shown ])
df_vat = pd.DataFrame([x if str(x)!='None' else dict({}) for x in orders.vat ])
orders=pd.merge(orders,df_shown, left_index=True, right_index=True)
orders=pd.merge(orders,df_vat, left_index=True, right_index=True)

pick_drop=pd.read_sql_query('''
        SELECT 
        delivery
        ,order_flow_event
        ,max(creation_date + 3 * INTERVAL '1 hour') as creation_date
        FROM public.order_flow_history
        where creation_date + 3 * INTERVAL '1 hour' >cast(now() as date) -1
        and creation_date + 3 * INTERVAL '1 hour' <cast(now() as date)
        and order_flow_event in ('AT_PICK_UP','ON_THE_WAY_TO_DROP_OFF')
        group by
        delivery
        ,order_flow_event
        ''', engineDelivery)

df=pick_drop.set_index(['delivery', 'order_flow_event']).unstack(level=-1).reset_index()

df.columns=['delivery','AT_PICK_UP','ON_THE_WAY_TO_DROP_OFF']

rating=pd.read_sql_query('''
SELECT  
order_id
,max(rating) as rating
FROM feedback
where to_type='DRIVER'
and from_type='USER'
and creation_date + 3 * INTERVAL '1 hour' >cast(now() as date) -1
and creation_date + 3 * INTERVAL '1 hour' <cast(now() as date)
group by
order_id
;
''', engineDelivery)

user = pd.read_sql_query('''
SELECT * 
from user_phone
;
''', engineUser)

tmp = pd.merge(orders,df, how='left',left_on='id', right_on='delivery' )

tmp = pd.merge(tmp,rating, how='left',left_on='id', right_on='order_id' )

tmp = pd.merge(tmp,user, how='left',left_on='customer_user_id', right_on='id' ).rename(columns={'normalized_value':'customer phone'})

tmp = pd.merge(tmp,user, how='left',left_on='drop_off_user_id', right_on='id' ).rename(columns={'normalized_value':'drop_off_user_phone'})

fino=pd.merge(tmp, driver_info[['driver_id','first_name','last_name']], how='left', left_on='driver', right_on='driver_id')

#cumul driver report

cumul = fino.groupby(by=['driver','status']).id_x.count().reset_index()

tmp=pd.pivot_table(data=cumul, index='driver', columns='status').id_x.reset_index()

tmp['total'] = tmp['CANCELLED'].fillna(0) + tmp['COMPLETED'].fillna(0)

tmp = pd.merge(tmp,driver_online,how='left', left_on='driver', right_on='driver_id' ).drop(columns=['driver_id','day_online_report'])

fin_driver_cumul = pd.merge(tmp, finance_pivot, how='left', left_on='driver', right_on='beneficiary_id' )

writer = pd.ExcelWriter(r'ExampleReportOperations.xlsx', engine='xlsxwriter')

# Write each dataframe to a different worksheet.
fin_driver_cumul.to_excel(writer, sheet_name='Report', index=False)
fino.to_excel(writer, sheet_name='OrderReport', index=False)
fin.to_excel(writer, sheet_name='DriverReport', index=False)
# Close the Pandas Excel writer and output the Excel file.
writer.save() 

